import streamlit as st
from PIL import Image
import pickle
import pandas as pd
import numpy as np
import scipy.sparse as sp

st.set_page_config(page_title="Sentiment Analysis System", page_icon=":shopping_cart:", layout="wide")

# Sidebar for navigation
# Todo: 
#   Move tÃªn thÃ nh viÃªn qua sidebar -> done
#   Home + Hasaki + Project Summary vÃ o 1 trang. -> process
#   Build Model 1 trang
#  Sentiment Analysis 1 trang
#  Product Analysis 1 trang




menu = ["NewPage", "Home", "Hasaki",'Project Summary', '', "Sentiment Analysis", "Product Analysis"]
st.sidebar.title("Äá»“ Ãn Tá»‘t Nghiá»‡p")
st.sidebar.markdown(
    """
    <h2 style="display: flex; align-items: center; font-size: 18px;">
        <span style="margin-left: 8px;">Sentiment Analysis Project</span>
    </h2>
    """,
    unsafe_allow_html=True,
)

page = st.sidebar.selectbox("Chá»©c NÄƒng", menu)

# Subheader with an icon for "Giáº£ng viÃªn hÆ°á»›ng dáº«n"
st.sidebar.markdown(
    """
    <h3 style="display: flex; align-items: center; font-size: 18px;">
        <span style="margin-left: 8px;">Giáº£ng viÃªn hÆ°á»›ng dáº«n</span>
    </h3>
    """,
    unsafe_allow_html=True,
)
st.sidebar.markdown("ğŸ‘©â€ğŸ« [Tháº¡c SÄ© Khuáº¥t ThÃ¹y PhÆ°Æ¡ng](https://csc.edu.vn/giao-vien~37#)")

# Subheader with an icon for "ThÃ nh ViÃªn"
st.sidebar.markdown(
    """
    <style>
        .footer {
            text-align: center;
            font-size: 12px;
        }
        hr {
            border: 0.5px solid gray;
        }
    </style>
    <div class="footer">
        <hr>
    </div>
    """,
    unsafe_allow_html=True,
)
st.sidebar.markdown(
    """
    <h3 style="display: flex; align-items: center; font-size: 18px;">
        <span style="margin-left: 8px;">ThÃ nh ViÃªn</span>
    </h3>
    """,
    unsafe_allow_html=True,
)
st.sidebar.markdown(" :boy: MÃ£ Tháº¿ Nhá»±t")
st.sidebar.markdown(" :girl: Tá»« Thá»‹ Thanh XuÃ¢n")

# Subheader with an icon for "NgÃ y bÃ¡o cÃ¡o tá»‘t nghiá»‡p"
st.sidebar.markdown(
    """
    <style>
        .footer {
            text-align: center;
            font-size: 12px;
        }
        hr {
            border: 0.5px solid gray;
        }
    </style>
    <div class="footer">
        <hr>
    </div>
    """,
    unsafe_allow_html=True,
)

st.sidebar.markdown(
    """
    <h3 style="display: flex; align-items: center; font-size: 18px;">
        <span style="margin-left: 8px;">NgÃ y bÃ¡o cÃ¡o tá»‘t nghiá»‡p:</span>
    </h3>
    """,
    unsafe_allow_html=True,
)
st.sidebar.write('ğŸ“… 16/12/2024')

# Add spacer for footer positioning
st.sidebar.markdown("<div style='height: 100px;'></div>", unsafe_allow_html=True)

# Sidebar footer
st.sidebar.write("Â© 2024 Hasaki Sentiment Analysis System")


# Main page logic
if page == "NewPage":
    # Banner Image
    image = Image.open("src/images/hasaki_banner.jpg")
    st.image(image, 
             use_container_width=True)

    tab_containers = st.tabs(['Hasaki Project', 'Má»¥c TiÃªu Dá»± Ãn', 'Thá»±c Hiá»‡n Dá»± Ãn'])

    with tab_containers[0]:
        # Title Section
        st.title("Dá»± Ã¡n HASAKI: PhÃ¢n tÃ­ch pháº£n há»“i khÃ¡ch hÃ ng ğŸ›ï¸")

        # Introduction Section
        st.subheader("1. Tá»•ng quan vá» HASAKI")
        st.markdown("""
        **HASAKI.VN** lÃ  há»‡ thá»‘ng cá»­a hÃ ng má»¹ pháº©m chÃ­nh hÃ£ng vÃ  dá»‹ch vá»¥ chÄƒm sÃ³c sáº¯c Ä‘áº¹p chuyÃªn sÃ¢u, vá»›i:  
        - ğŸ›’ **Há»‡ thá»‘ng cá»­a hÃ ng tráº£i dÃ i trÃªn toÃ n quá»‘c.**  
        - ğŸ¤ **LÃ  Ä‘á»‘i tÃ¡c phÃ¢n phá»‘i chiáº¿n lÆ°á»£c táº¡i Viá»‡t Nam** cá»§a hÃ ng loáº¡t thÆ°Æ¡ng hiá»‡u má»¹ pháº©m lá»›n.  
        - ğŸŒ **Ná»n táº£ng trá»±c tuyáº¿n** giÃºp khÃ¡ch hÃ ng dá»… dÃ ng:
            - Lá»±a chá»n sáº£n pháº©m.  
            - Xem Ä‘Ã¡nh giÃ¡/nháº­n xÃ©t thá»±c táº¿.  
            - Äáº·t mua hÃ ng nhanh chÃ³ng.  
        """)

        # Problem Section
        st.subheader("2. Váº¥n Ä‘á» Ä‘áº·t ra ğŸš©")
        st.markdown("""
        ğŸ§ **CÃ¢u há»i Ä‘áº·t ra:**  
        - LÃ m tháº¿ nÃ o Ä‘á»ƒ **cÃ¡c nhÃ£n hÃ ng hiá»ƒu rÃµ hÆ¡n vá» khÃ¡ch hÃ ng**?  
        - LÃ m sao Ä‘á»ƒ biáº¿t **khÃ¡ch hÃ ng Ä‘Ã¡nh giÃ¡ gÃ¬ vá» sáº£n pháº©m**?  
        - LÃ m cÃ¡ch nÃ o Ä‘á»ƒ tá»« pháº£n há»“i Ä‘Ã³, cÃ¡c nhÃ£n hÃ ng cÃ³ thá»ƒ:  
            - **Cáº£i thiá»‡n cháº¥t lÆ°á»£ng sáº£n pháº©m.**  
            - **NÃ¢ng cáº¥p dá»‹ch vá»¥ Ä‘i kÃ¨m.**  

        **Hasaki.vn sá»Ÿ há»¯u lÆ°á»£ng lá»›n dá»¯ liá»‡u tá»« cÃ¡c bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng, tuy nhiÃªn:**
        - ğŸš« **KhÃ´ng thá»ƒ xá»­ lÃ½ pháº£n há»“i nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c.**  
        - ğŸ¤” **KhÃ³ xÃ¡c Ä‘á»‹nh pháº£n há»“i tÃ­ch cá»±c, tiÃªu cá»±c hay trung tÃ­nh.**  
        - ğŸ•’ **Tá»‘n thá»i gian Ä‘á»ƒ sá»­ dá»¥ng pháº£n há»“i cho viá»‡c cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥.**
        """)

        # Objective Section
        st.subheader("3. Má»¥c tiÃªu ğŸ¯")
        st.markdown("""
        ğŸ› ï¸ **XÃ¢y dá»±ng há»‡ thá»‘ng dá»± Ä‘oÃ¡n cáº£m xÃºc trong pháº£n há»“i khÃ¡ch hÃ ng**:
        1. **PhÃ¢n loáº¡i cÃ¡c bÃ¬nh luáº­n thÃ nh 2 loáº¡i**: TÃ­ch Cá»±c, TiÃªu Cá»±c.
        2. **ÄÃ¡nh giÃ¡ chi tiáº¿t tá»«ng sáº£n pháº©m dá»±a vÃ o cÃ¡c bÃ¬nh luáº­n.** 
        3. **GiÃºp Hasaki vÃ  Ä‘á»‘i tÃ¡c**:
            - Hiá»ƒu nhanh Ã½ kiáº¿n khÃ¡ch hÃ ng.
            - **Cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥** dá»±a trÃªn pháº£n há»“i thá»±c táº¿.
            - **TÄƒng má»©c Ä‘á»™ hÃ i lÃ²ng vÃ  trung thÃ nh** cá»§a khÃ¡ch hÃ ng.
        """)

        # Expected Outcomes Section
        st.subheader("4. Káº¿t quáº£ ká»³ vá»ng âœ…")
        st.markdown("""
        - **ChÃ­nh xÃ¡c â‰¥90%** trong phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.  
        - **Cung cáº¥p phÃ¢n tÃ­ch thá»i gian thá»±c** cho Hasaki vÃ  Ä‘á»‘i tÃ¡c.  
        - TÄƒng sá»± **hÃ i lÃ²ng** vÃ  **lÃ²ng trung thÃ nh** cá»§a khÃ¡ch hÃ ng thÃ´ng qua cÃ¡c cáº£i tiáº¿n.
        """)

        
          
    with tab_containers[1]:  # Assuming the second tab is for the project process
        st.subheader("Quy trÃ¬nh thá»±c hiá»‡n ğŸ’¡")

        # Step 1: Data Collection
        st.subheader("1. Thu tháº­p dá»¯ liá»‡u ğŸ“")
        st.markdown("""
        - **Nguá»“n dá»¯ liá»‡u:** BÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ tá»« khÃ¡ch hÃ ng trÃªn Hasaki.vn.  
        - **Má»¥c tiÃªu:** Táº¡o táº­p dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao Ä‘á»ƒ Ä‘Ã o táº¡o vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh há»c mÃ¡y.
        """)
        image = Image.open("src/images/rv2.png")
        st.image(image, caption="ÄÃ¡nh giÃ¡ vá» sáº£n pháº©m nÆ°á»›c Hoa Há»“ng Klairs KhÃ´ng MÃ¹i Cho Da Nháº¡y Cáº£m 180ml Supple Preparation Unscented Toner",
                  use_container_width=True)
    
     

        # Step 2: Data Processing Section
        st.subheader("2. Xá»­ lÃ½ dá»¯ liá»‡u ğŸ”„")

        st.markdown("""
        ### Má»¥c tiÃªu:
        Chuáº©n bá»‹ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u bÃ¬nh luáº­n Ä‘á»ƒ sáºµn sÃ ng cho cÃ¡c bÆ°á»›c phÃ¢n tÃ­ch vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.

        ### Quy trÃ¬nh xá»­ lÃ½:
        1. **LÃ m sáº¡ch dá»¯ liá»‡u:**
        - Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t (vÃ­ dá»¥: `!`, `@`, `#`, ...).
        - XÃ³a sá»‘ vÃ  cÃ¡c tá»« khÃ´ng mang Ã½ nghÄ©a ngá»¯ nghÄ©a (stop words).
        2. **Chuáº©n hÃ³a vÄƒn báº£n:**
        - Chuyá»ƒn toÃ n bá»™ vÄƒn báº£n vá» chá»¯ thÆ°á»ng.
        - Chuáº©n hÃ³a kÃ½ tá»± láº·p láº¡i (vÃ­ dá»¥: `"Ä‘áº¹p quÃ¡aaa"` â†’ `"Ä‘áº¹p quÃ¡"`).
        - Sá»­ dá»¥ng cÃ´ng cá»¥ NLP Ä‘á»ƒ tÃ¡ch tá»« vÃ  chuáº©n bá»‹ dá»¯ liá»‡u.
        3. **Chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯:**
        - Thay tháº¿ cÃ¡c tá»« teencode thÃ nh dáº¡ng chuáº©n (vÃ­ dá»¥: `"hok"` â†’ `"khÃ´ng"`).
        - Dá»‹ch tá»« tiáº¿ng Anh sang tiáº¿ng Viá»‡t (náº¿u cÃ³).
        4. **Xá»­ lÃ½ ngá»¯ phÃ¡p (POS Tagging):**
        - PhÃ¢n tÃ­ch tá»« loáº¡i vÃ  gÃ¡n nhÃ£n tá»« vá»±ng Ä‘á»ƒ hiá»ƒu cáº¥u trÃºc cÃ¢u.
        5. **Táº¡o phÃ¢n Ä‘oáº¡n (Chunking):**
        - Chia nhá» vÄƒn báº£n thÃ nh cÃ¡c khá»‘i thÃ´ng tin cÃ³ Ã½ nghÄ©a Ä‘á»ƒ dá»… dÃ ng xá»­ lÃ½ vÃ  phÃ¢n tÃ­ch.

        ### Káº¿t quáº£ ká»³ vá»ng:
        - Dá»¯ liá»‡u sáº¡ch vÃ  chuáº©n hÃ³a, lÆ°u trá»¯ dÆ°á»›i dáº¡ng cá»™t vÄƒn báº£n Ä‘Ã£ xá»­ lÃ½ vÃ  phÃ¢n Ä‘oáº¡n.
        """)
        image = Image.open("src/images/output1.png")
        st.image(image, caption="Ná»™i dung bÃ¬nh luáº­n trÆ°á»›c vÃ  sau khi xá»­ lÃ½",
                  use_container_width=True)
        
        # Step 3: Labeling and Sentiment Analysis Section
        st.subheader("3. Gáº¯n nhÃ£n vÃ  phÃ¢n tÃ­ch cáº£m xÃºc ğŸ·ï¸ğŸ“Š")

        st.markdown("""
        ### Má»¥c tiÃªu:
        - Gáº¯n nhÃ£n (label) cho dá»¯ liá»‡u bÃ¬nh luáº­n Ä‘á»ƒ sá»­ dá»¥ng trong phÃ¢n tÃ­ch cáº£m xÃºc hoáº·c cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y giÃ¡m sÃ¡t.
        - PhÃ¢n tÃ­ch sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo sáº£n pháº©m vÃ  cáº£m xÃºc (tÃ­ch cá»±c hoáº·c tiÃªu cá»±c), Ä‘á»“ng thá»i tÃ­nh tá»· lá»‡ cáº£m xÃºc Ä‘á»ƒ hiá»ƒu rÃµ pháº£n há»“i cá»§a khÃ¡ch hÃ ng.

        ### Quy trÃ¬nh thá»±c hiá»‡n:
        1. **Gáº¯n nhÃ£n bÃ¬nh luáº­n:**
        - **XÃ¡c Ä‘á»‹nh tá»« tÃ­ch cá»±c vÃ  tiÃªu cá»±c:** TÃ¬m vÃ  Ä‘áº¿m cÃ¡c tá»« tÃ­ch cá»±c (vÃ­ dá»¥: `tá»‘t`, `Ä‘áº¹p`, `thÃ­ch`) vÃ  tiÃªu cá»±c (vÃ­ dá»¥: `xáº¥u`, `tá»‡`, `tháº¥t vá»ng`) trong bÃ¬nh luáº­n.
        - **TÃ­nh toÃ¡n tá»· lá»‡ tá»«:**
            - **Tá»· lá»‡ tá»« tÃ­ch cá»±c:** Tá»•ng sá»‘ tá»« tÃ­ch cá»±c chia cho tá»•ng sá»‘ tá»« trong bÃ¬nh luáº­n.
            - **Tá»· lá»‡ tá»« tiÃªu cá»±c:** Tá»•ng sá»‘ tá»« tiÃªu cá»±c chia cho tá»•ng sá»‘ tá»« trong bÃ¬nh luáº­n.
        - **PhÃ¢n loáº¡i bÃ¬nh luáº­n:**
            - **TÃ­ch cá»±c:** Khi tá»· lá»‡ tá»« tÃ­ch cá»±c cao hÆ¡n tiÃªu cá»±c vÃ  >= 2.
            - **TiÃªu cá»±c:** CÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i.

        2. **PhÃ¢n tÃ­ch cáº£m xÃºc theo sáº£n pháº©m:**
        - **Tá»•ng há»£p Ä‘Ã¡nh giÃ¡ theo sáº£n pháº©m vÃ  cáº£m xÃºc:**
            - Äáº¿m sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ tÃ­ch cá»±c vÃ  tiÃªu cá»±c theo tá»«ng sáº£n pháº©m.
            - Gá»™p táº¥t cáº£ cÃ¡c bÃ¬nh luáº­n, tá»« tÃ­ch cá»±c, vÃ  tá»« tiÃªu cá»±c thÃ nh chuá»—i vÄƒn báº£n.
        - **TÃ­nh tá»•ng sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ má»—i sáº£n pháº©m:** Tá»•ng sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ tá»« táº¥t cáº£ cÃ¡c cáº£m xÃºc cho tá»«ng sáº£n pháº©m.
        - **TÃ­nh tá»· lá»‡ cáº£m xÃºc:**
            - **CÃ´ng thá»©c:** `(Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo cáº£m xÃºc / Tá»•ng sá»‘ Ä‘Ã¡nh giÃ¡) * 100`.
            - Káº¿t quáº£ Ä‘Æ°á»£c lÆ°u trong cá»™t `Sentiment_Rate (%)`.

        ### Káº¿t quáº£ ká»³ vá»ng:
        - Dá»¯ liá»‡u bÃ¬nh luáº­n Ä‘Æ°á»£c gáº¯n nhÃ£n:
        - `1` cho bÃ¬nh luáº­n **tÃ­ch cá»±c**.
        - `0` cho bÃ¬nh luáº­n **tiÃªu cá»±c**.
        - Thá»‘ng kÃª sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ tÃ­ch cá»±c, tiÃªu cá»±c, vÃ  tá»•ng sá»‘ Ä‘Ã¡nh giÃ¡ theo tá»«ng sáº£n pháº©m.
        - TÃ­nh tá»· lá»‡ pháº§n trÄƒm cáº£m xÃºc tÃ­ch cá»±c hoáº·c tiÃªu cá»±c cho má»—i sáº£n pháº©m, há»— trá»£ phÃ¢n tÃ­ch xu hÆ°á»›ng cáº£m xÃºc cá»§a khÃ¡ch hÃ ng.
        """)
        image = Image.open("src/images/label.png")
        st.image(image, caption="Dá»¯ liá»‡u sau khi Ä‘Æ°á»£c label",
                  use_container_width=True)
        # Step 4: Detailed Product Analysis Section
        st.subheader("4. PhÃ¢n tÃ­ch chi tiáº¿t sáº£n pháº©m ğŸ›ï¸")

        st.markdown("""
        ### Má»¥c tiÃªu:
        Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» sáº£n pháº©m, bao gá»“m:
        - ThÃ´ng tin cÆ¡ báº£n (tÃªn sáº£n pháº©m, giÃ¡ bÃ¡n, mÃ´ táº£, Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ trung bÃ¬nh).
        - PhÃ¢n tÃ­ch Ä‘Ã¡nh giÃ¡ cáº£m xÃºc (tÃ­ch cá»±c vÃ  tiÃªu cá»±c).
        - HÃ¬nh dung dá»¯ liá»‡u thÃ´ng qua biá»ƒu Ä‘á»“ vÃ  Word Cloud.

        ### Quy trÃ¬nh:
        1. **Hiá»ƒn thá»‹ thÃ´ng tin cÆ¡ báº£n vá» sáº£n pháº©m**:
        - TÃªn sáº£n pháº©m, giÃ¡ bÃ¡n, giÃ¡ gá»‘c, phÃ¢n loáº¡i, mÃ´ táº£, Ä‘iá»ƒm Ä‘Ã¡nh giÃ¡ trung bÃ¬nh.
        2. **PhÃ¢n tÃ­ch Ä‘Ã¡nh giÃ¡ cáº£m xÃºc**:
        - Hiá»ƒn thá»‹ tá»· lá»‡ cáº£m xÃºc tÃ­ch cá»±c vÃ  tiÃªu cá»±c báº±ng biá»ƒu Ä‘á»“ hÃ¬nh trÃ²n.
        - Táº¡o Word Cloud cho cÃ¡c tá»« tÃ­ch cá»±c vÃ  tiÃªu cá»±c.
        3. **Kiá»ƒm tra dá»¯ liá»‡u**:
        - Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u, thÃ´ng bÃ¡o sáº½ Ä‘Æ°á»£c hiá»ƒn thá»‹ Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t.
        """)
        image = Image.open("src/images/info.png")
        st.image(image, caption="ThÃ´ng tin sáº£n pháº©m báº¡n Ä‘ang tÃ¬m kiáº¿m",
                  use_container_width=True)
        image = Image.open("src/images/pie.png")
        st.image(image, caption="ThÃ´ng tin sáº£n pháº©m báº¡n Ä‘ang tÃ¬m kiáº¿m",
                  use_container_width=True)
        from PIL import Image

        # Center the title using HTML
        st.markdown(
            """
            <h3 style="text-align: center;">Word Cloud - Positive and Negative Sentiment:</h3>
            """,
            unsafe_allow_html=True
        )

        # Display Positive and Negative Word Cloud Images Side-by-Side
        cols = st.columns(2)

        # Positive Word Cloud
        with cols[0]:
            image = Image.open("src/images/pos.png")
            st.image(image, caption="Top 50 tá»« tÃ­ch cá»±c vá» sáº£n pháº©m", use_container_width=True)

        # Negative Word Cloud
        with cols[1]:
            image = Image.open("src/images/neg.png")
            st.image(image, caption="Top 50 tá»« tiÃªu cá»±c vá» sáº£n pháº©m", use_container_width=True)

        # Step 5: Data Preparation for Machine Learning
        st.subheader("5. Chuáº©n bá»‹ dá»¯ liá»‡u cho MÃ´ hÃ¬nh Há»c mÃ¡y ğŸ¤–")

        st.markdown("""
        ### Má»¥c tiÃªu:
        Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘áº§u vÃ o cháº¥t lÆ°á»£ng cao cho cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y báº±ng cÃ¡ch:
        - Biáº¿n Ä‘á»•i vÄƒn báº£n thÃ nh Ä‘áº·c trÆ°ng sá»‘ sá»­ dá»¥ng TF-IDF.
        - Bá»• sung cÃ¡c Ä‘áº·c trÆ°ng há»— trá»£ phÃ¢n tÃ­ch (Ä‘á»™ dÃ i Ä‘Ã¡nh giÃ¡).
        - Xá»­ lÃ½ máº¥t cÃ¢n báº±ng lá»›p Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh.

        ### Quy trÃ¬nh:
        1. **PhÃ¢n chia dá»¯ liá»‡u:**
            - TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n (80%) vÃ  táº­p kiá»ƒm tra (20%).
        2. **Biáº¿n Ä‘á»•i vÄƒn báº£n báº±ng TF-IDF:**
            - Sá»­ dá»¥ng `TfidfVectorizer` Ä‘á»ƒ táº¡o Ä‘áº·c trÆ°ng tá»« vÄƒn báº£n (giá»¯ láº¡i 5000 tá»« quan trá»ng nháº¥t).
        3. **ThÃªm Ä‘áº·c trÆ°ng há»— trá»£:**
            - TÃ­nh Ä‘á»™ dÃ i vÄƒn báº£n vÃ  chuáº©n hÃ³a báº±ng `MinMaxScaler`.
        4. **Káº¿t há»£p Ä‘áº·c trÆ°ng:**
            - Káº¿t há»£p TF-IDF vÃ  Ä‘áº·c trÆ°ng Ä‘á»™ dÃ i thÃ nh má»™t ma tráº­n Ä‘áº§u vÃ o duy nháº¥t.
        5. **Xá»­ lÃ½ máº¥t cÃ¢n báº±ng lá»›p:**
            - Ãp dá»¥ng SMOTE Ä‘á»ƒ táº¡o thÃªm dá»¯ liá»‡u cho lá»›p nhá», Ä‘áº£m báº£o dá»¯ liá»‡u cÃ¢n báº±ng.
        """)

        # Step 6: Evaluation and Improvement
        st.subheader("6. ÄÃ¡nh giÃ¡ vÃ  cáº£i thiá»‡n ğŸ“Š")

        st.markdown("""
        ### TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡:
        1. **Äá»™ chÃ­nh xÃ¡c (Accuracy):** XÃ¡c Ä‘á»‹nh tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng.
        2. **F1-Score:** Äo lÆ°á»ng cÃ¢n báº±ng giá»¯a Precision vÃ  Recall.
        3. **ROC-AUC:** Hiá»‡u quáº£ phÃ¢n loáº¡i dá»±a trÃªn Ä‘Æ°á»ng cong ROC.

        ### Quy trÃ¬nh cáº£i thiá»‡n:
        - Dá»±a trÃªn cÃ¡c chá»‰ sá»‘ vÃ  pháº£n há»“i tá»« ngÆ°á»i dÃ¹ng há»‡ thá»‘ng.
        - Thá»­ nghiá»‡m thÃªm cÃ¡c mÃ´ hÃ¬nh hoáº·c Ä‘áº·c trÆ°ng bá»• sung.
        """)
        # Step 7: Model Comparison and Recommendation
        st.subheader("7. So sÃ¡nh vÃ  lá»±a chá»n mÃ´ hÃ¬nh tá»‘i Æ°u ğŸ“Š")

        st.markdown("""
        ### Má»¥c tiÃªu:
        So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh Logistic Regression, Multinomial Naive Bayes, XGBoost, vÃ  SVM.
        ÄÆ°a ra lá»±a chá»n mÃ´ hÃ¬nh tá»‘i Æ°u cho bÃ i toÃ¡n phÃ¢n loáº¡i cáº£m xÃºc.
        """)

        # Display Comparison Table
        st.markdown("### Báº£ng so sÃ¡nh hiá»‡u suáº¥t cÃ¡c mÃ´ hÃ¬nh:")

        comparison_data = {
            "Metric": ["Accuracy", "Precision (Class 0)", "Precision (Class 1)", "Recall (Class 0)", "Recall (Class 1)", "F1-Score (Class 0)", "F1-Score (Class 1)", "ROC-AUC Score"],
            "Logistic Regression": [0.9778, 0.63, 1.00, 0.96, 0.98, 0.76, 0.99, 0.99],
            "Multinomial Naive Bayes": [0.9639, 0.50, 1.00, 0.96, 0.96, 0.66, 0.98, 0.99],
            "XGBoost": [0.9849, 0.73, 1.00, 0.93, 0.99, 0.82, 0.99, 0.99],
            "SVM": [0.9776, 0.62, 1.00, 0.97, 0.98, 0.76, 0.99, 0.99]
        }

        df_comparison = pd.DataFrame(comparison_data)
        st.dataframe(df_comparison)

        # Recommendation Section
        st.markdown("### Lá»±a chá»n mÃ´ hÃ¬nh tá»‘i Æ°u ğŸ“Œ")

        st.markdown("""
        #### LÃ½ do lá»±a chá»n Logistic Regression:
        1. **Dá»… hiá»ƒu vÃ  giáº£i thÃ­ch**:
            - Logistic Regression giÃºp xÃ¡c Ä‘á»‹nh rÃµ rÃ ng táº§m quan trá»ng cá»§a tá»«ng Ä‘áº·c trÆ°ng (tá»« khÃ³a) trong dá»± Ä‘oÃ¡n.
            - ThÃ­ch há»£p cho cÃ¡c bÃ i toÃ¡n cáº§n minh báº¡ch káº¿t quáº£.

        2. **Hiá»‡u suáº¥t á»•n Ä‘á»‹nh**:
            - Äá»™ chÃ­nh xÃ¡c Ä‘áº¡t **97.78%**, gáº§n tÆ°Æ¡ng Ä‘Æ°Æ¡ng XGBoost.
            - F1-Score cho cáº£ hai lá»›p (TÃ­ch cá»±c, TiÃªu cá»±c) ráº¥t tá»‘t.

        3. **ÄÆ¡n giáº£n vÃ  hiá»‡u quáº£**:
            - YÃªu cáº§u Ã­t tÃ i nguyÃªn tÃ­nh toÃ¡n.
            - Dá»… dÃ ng triá»ƒn khai vÃ o há»‡ thá»‘ng thá»±c táº¿.

        4. **Kháº£ nÄƒng má»Ÿ rá»™ng**:
            - ThÃ­ch há»£p vá»›i dá»¯ liá»‡u lá»›n vÃ  dá»… dÃ ng nÃ¢ng cáº¥p khi cÃ³ thÃªm dá»¯ liá»‡u má»›i.

        #### So sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c:
        - **XGBoost**: Máº·c dÃ¹ chÃ­nh xÃ¡c hÆ¡n nhÆ°ng phá»©c táº¡p vÃ  Ä‘Ã²i há»i nhiá»u tÃ i nguyÃªn.
        - **SVM**: CÃ¢n báº±ng hiá»‡u suáº¥t nhÆ°ng máº¥t thá»i gian trong huáº¥n luyá»‡n khi dá»¯ liá»‡u lá»›n.
        - **Multinomial Naive Bayes**: Nhanh nhÆ°ng hiá»‡u suáº¥t tháº¥p hÆ¡n Logistic Regression.
        """)

        

        # Step 8: System Deployment
        st.subheader("8. Triá»ƒn khai há»‡ thá»‘ng ğŸš€")

        st.markdown("""
        ### Má»¥c tiÃªu:
        Triá»ƒn khai mÃ´ hÃ¬nh há»c mÃ¡y vÃ o há»‡ thá»‘ng thá»±c táº¿ Ä‘á»ƒ há»— trá»£ quáº£n lÃ½ sáº£n pháº©m vÃ  dá»‹ch vá»¥.

        ### Ná»™i dung triá»ƒn khai:
        1. **TÃ­ch há»£p mÃ´ hÃ¬nh trÃªn ná»n táº£ng Hasaki.vn:**
            - PhÃ¢n loáº¡i pháº£n há»“i cá»§a khÃ¡ch hÃ ng theo thá»i gian thá»±c.
            - PhÃ¢n tÃ­ch cáº£m xÃºc Ä‘á»ƒ cung cáº¥p thÃ´ng tin há»¯u Ã­ch cho nhÃ  quáº£n lÃ½.
        2. **Hiá»ƒn thá»‹ bÃ¡o cÃ¡o chi tiáº¿t:**
            - Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n tÃ­ch cá»±c/tiÃªu cá»±c.
            - Xu hÆ°á»›ng cáº£m xÃºc theo sáº£n pháº©m/dá»‹ch vá»¥.
        """)

    with tab_containers[2]:
        st.title("Quy trÃ¬nh thá»±c hiá»‡n dá»± Ã¡n ğŸ›ï¸")
        # Objective Section
        st.subheader("1. Má»¥c tiÃªu ğŸ¯")
        st.markdown("""
        ğŸ› ï¸ **XÃ¢y dá»±ng há»‡ thá»‘ng dá»± Ä‘oÃ¡n cáº£m xÃºc trong pháº£n há»“i khÃ¡ch hÃ ng**:
        1. **PhÃ¢n loáº¡i cÃ¡c bÃ¬nh luáº­n thÃ nh 2 loáº¡i**: TÃ­ch Cá»±c, TiÃªu Cá»±c
        2. **ÄÃ¡nh giÃ¡ chi tiáº¿t tá»«ng sáº£n pháº©m dá»±a vÃ o cÃ¡c bÃ¬nh luáº­n** 
        3. **GiÃºp Hasaki vÃ  Ä‘á»‘i tÃ¡c**:
            - Hiá»ƒu nhanh Ã½ kiáº¿n khÃ¡ch hÃ ng.
            - **Cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥** dá»±a trÃªn pháº£n há»“i thá»±c táº¿.
            - **TÄƒng má»©c Ä‘á»™ hÃ i lÃ²ng vÃ  trung thÃ nh** cá»§a khÃ¡ch hÃ ng.
        """)

        # Solution Section
        st.subheader("2. Giáº£i phÃ¡p ğŸ’¡")
        st.markdown("""
        ğŸ› ï¸ **Há»‡ thá»‘ng dá»± Ä‘oÃ¡n pháº£n há»“i sáº½ Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i cÃ¡c bÆ°á»›c**:
        1. **Thu tháº­p dá»¯ liá»‡u**: Tá»« pháº§n bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng trÃªn Hasaki.vn.  
        2. **Xá»­ lÃ½ dá»¯ liá»‡u**:
            - LÃ m sáº¡ch dá»¯ liá»‡u (loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, stop words).
            - Chuáº©n hÃ³a vÄƒn báº£n (chuyá»ƒn vá» chá»¯ thÆ°á»ng, tÃ¡ch tá»« báº±ng NLP).  
        3. **XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y**:
            - Logistic Regression, Random Forest, hoáº·c mÃ´ hÃ¬nh transformer nhÆ° BERT.  
        4. **Triá»ƒn khai há»‡ thá»‘ng**:
            - TÃ­ch há»£p mÃ´ hÃ¬nh trÃªn website Ä‘á»ƒ phÃ¢n loáº¡i pháº£n há»“i theo thá»i gian thá»±c.
        5. **ÄÃ¡nh giÃ¡ vÃ  cáº£i thiá»‡n**:
            - Dá»±a trÃªn chá»‰ sá»‘ Precision, Recall, F1-Score.
            - Dá»±c trÃªn cÃ¡c reports: classification report, ROC_curve,...
        """)

        # Expected Outcomes Section
        st.subheader("3. Káº¿t quáº£ ká»³ vá»ng âœ…")
        st.markdown("""
        - **ChÃ­nh xÃ¡c â‰¥90%** trong phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.  
        - **Cung cáº¥p phÃ¢n tÃ­ch thá»i gian thá»±c** cho Hasaki vÃ  Ä‘á»‘i tÃ¡c.  
        - TÄƒng sá»± **hÃ i lÃ²ng** vÃ  **lÃ²ng trung thÃ nh** cá»§a khÃ¡ch hÃ ng thÃ´ng qua cÃ¡c cáº£i tiáº¿n.
        """)


#####################################

elif page == "Home":
    # Banner Image
    image = Image.open("src/images/hasaki_banner_2.jpg")
    st.image(image, caption="Sentiment Analysis - Understand Your Customers", use_container_width=True)

    # Project Objective
    st.header("Project Objective")
    st.markdown("""
        This project focuses on developing a **Sentiment Analysis System** to:
        - Analyze customer feedback and reviews.
        - Classify sentiments into categories: **Positive**, **Negative**.
        - Provide actionable insights to improve products and services.
    """)

    # Display Lottie Animation
    image = Image.open("src/images/home.png")
    st.image(image, caption="Sentiment Analysis - Understand Your Customers", use_container_width=True)

    # Methodology
    st.header("Methodology ğŸ“‹")
    st.markdown("""
    ğŸ¤– **Steps to Build the Sentiment Analysis System**:  
    1. **Data Collection**: Collect feedback and reviews from various platforms.  
    2. **Data Preprocessing**: Clean and preprocess the text data using NLP techniques.  
    3. **Model Training**: Train machine learning or deep learning models to classify sentiments.  
    4. **Deployment**: Integrate the sentiment classifier into a real-time system for actionable insights.
    """)

    # Team Section
    st.header("Our Team")
    col1, col2 = st.columns(2)

    with col1:
        st.write("### MÃ£ Tháº¿ Nhá»±t")
        # image1 = Image.open("src/images/A.jpg")
        # st.image(image1, caption="MÃ£ Tháº¿ Nhá»±t - Data Scientist", use_container_width=True)

    with col2:
        st.write("### Tá»« Thá»‹ Thanh XuÃ¢n")
        # image2 = Image.open("src/images/B.jpg")
        # st.image(image2, caption="Tá»« Thá»‹ Thanh XuÃ¢n - Machine Learning Engineer", use_container_width=True)

    # Footer
    st.markdown("""
    ---
    **Â© 2024 Sentiment Analysis System** | Developed with â¤ï¸ by [MÃ£ Tháº¿ Nhá»±t & Tá»« Thá»‹ Thanh XuÃ¢n]
    """)

#####################################

elif page == "Hasaki":
    
    # Title
    st.title("ğŸŒŸ **Giá»›i thiá»‡u vá» HASAKI Project** ğŸŒŸ")
    # Banner Image
    image = Image.open("src/images/hasaki_banner_2.jpg")
    st.image(image, caption="Hasaki.VN - Quality & Trust", use_container_width=True)
    # Introduction Section
    st.subheader("1. Tá»•ng quan vá» HASAKI")
    st.markdown("""
    **HASAKI.VN** lÃ  há»‡ thá»‘ng cá»­a hÃ ng má»¹ pháº©m chÃ­nh hÃ£ng vÃ  dá»‹ch vá»¥ chÄƒm sÃ³c sáº¯c Ä‘áº¹p chuyÃªn sÃ¢u, vá»›i:  
    - ğŸ›’ **Há»‡ thá»‘ng cá»­a hÃ ng tráº£i dÃ i trÃªn toÃ n quá»‘c.**  
    - ğŸ¤ **LÃ  Ä‘á»‘i tÃ¡c phÃ¢n phá»‘i chiáº¿n lÆ°á»£c táº¡i Viá»‡t Nam** cá»§a hÃ ng loáº¡t thÆ°Æ¡ng hiá»‡u má»¹ pháº©m lá»›n.  
    - ğŸŒ **Ná»n táº£ng trá»±c tuyáº¿n** giÃºp khÃ¡ch hÃ ng dá»… dÃ ng:
        - Lá»±a chá»n sáº£n pháº©m.  
        - Xem Ä‘Ã¡nh giÃ¡/nháº­n xÃ©t thá»±c táº¿.  
        - Äáº·t mua hÃ ng nhanh chÃ³ng.  
    """)

    # Divider
    st.divider()

    # Problem Section
    st.subheader("2. Váº¥n Ä‘á» Ä‘áº·t ra ğŸš©")
    st.markdown("""
    ğŸ§ **CÃ¢u há»i Ä‘áº·t ra:**  
    - LÃ m tháº¿ nÃ o Ä‘á»ƒ **cÃ¡c nhÃ£n hÃ ng hiá»ƒu rÃµ hÆ¡n vá» khÃ¡ch hÃ ng**?  
    - LÃ m sao Ä‘á»ƒ biáº¿t **khÃ¡ch hÃ ng Ä‘Ã¡nh giÃ¡ gÃ¬ vá» sáº£n pháº©m**?  
    - LÃ m cÃ¡ch nÃ o Ä‘á»ƒ tá»« pháº£n há»“i Ä‘Ã³, cÃ¡c nhÃ£n hÃ ng cÃ³ thá»ƒ:  
        - **Cáº£i thiá»‡n cháº¥t lÆ°á»£ng sáº£n pháº©m.**  
        - **NÃ¢ng cáº¥p dá»‹ch vá»¥ Ä‘i kÃ¨m.**  
    """)

    # Divider
    st.divider()

    # Goal Section
    st.subheader("3. Má»¥c tiÃªu ğŸ¯")
    st.markdown("""
    - ğŸ’¡ **Thu tháº­p vÃ  phÃ¢n tÃ­ch Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng** Ä‘á»ƒ cung cáº¥p thÃ´ng tin giÃ¡ trá»‹ cho cÃ¡c nhÃ£n hÃ ng.  
    - ğŸ“Š GiÃºp cÃ¡c nhÃ£n hÃ ng hiá»ƒu sÃ¢u hÆ¡n vá» **sá»Ÿ thÃ­ch, nhu cáº§u vÃ  tráº£i nghiá»‡m thá»±c táº¿** cá»§a khÃ¡ch hÃ ng.  
    - ğŸš€ TÄƒng sá»± hÃ i lÃ²ng vÃ  trung thÃ nh cá»§a khÃ¡ch hÃ ng thÃ´ng qua viá»‡c cáº£i tiáº¿n sáº£n pháº©m vÃ  dá»‹ch vá»¥.
    """)

    # Divider
    st.divider()

    # Methodology Section
    st.subheader("4. PhÆ°Æ¡ng phÃ¡p ğŸ“‹")
    st.markdown("""
    ğŸ¤– **XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c/tiÃªu cá»±c**  
    1. **Thu tháº­p dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡** tá»« khÃ¡ch hÃ ng trÃªn ná»n táº£ng HASAKI.  
    2. **Xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)**:
        - Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t vÃ  tá»« dÆ° thá»«a.
        - TÃ¡ch tá»« vÃ  chuáº©n hÃ³a vÄƒn báº£n báº±ng cÃ´ng cá»¥ NLP nhÆ° `underthesea` hoáº·c ``.  
    3. **Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y**:
        - Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n nhÆ° Logistic Regression, Random Forest.  
    4. **PhÃ¢n loáº¡i cáº£m xÃºc**:
        - DÃ¡n nhÃ£n bÃ¬nh luáº­n: **TÃ­ch cá»±c** hoáº·c **TiÃªu cá»±c**.  
    5. **Triá»ƒn khai há»‡ thá»‘ng**:
        - TÃ­ch há»£p mÃ´ hÃ¬nh vÃ o ná»n táº£ng Ä‘á»ƒ xá»­ lÃ½ bÃ¬nh luáº­n trong thá»i gian thá»±c.  
    """)


    st.image(
    "src/images/1.jpg", 
    caption="âœ¨ **PhÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c vÃ  tiÃªu cá»±c** giÃºp nhÃ£n hÃ ng hiá»ƒu rÃµ hÆ¡n cáº£m xÃºc cá»§a khÃ¡ch hÃ ng vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng sáº£n pháº©m.",
    use_container_width=True,
    )

    st.markdown("""
    ğŸ’¡ **Minh há»a**:  
    - BÃ¬nh luáº­n tÃ­ch cá»±c Ä‘Æ°á»£c phÃ¢n tÃ­ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhá»¯ng Ä‘iá»ƒm ná»•i báº­t mÃ  khÃ¡ch hÃ ng yÃªu thÃ­ch.  
    - BÃ¬nh luáº­n tiÃªu cá»±c Ä‘Æ°á»£c khai thÃ¡c Ä‘á»ƒ tÃ¬m ra cÃ¡c váº¥n Ä‘á» cáº§n cáº£i thiá»‡n.  
    ğŸ“Š **TÄƒng kháº£ nÄƒng hÃ nh Ä‘á»™ng:** Giáº£i phÃ¡p nÃ y giÃºp nhÃ£n hÃ ng tá»‘i Æ°u hÃ³a sáº£n pháº©m vÃ  dá»‹ch vá»¥.
    """)

    # Divider
    st.divider()

    # Call-to-Action
    st.markdown("""
    ğŸ’¡ **Káº¿t quáº£ ká»³ vá»ng**:  
    - PhÃ¢n loáº¡i chÃ­nh xÃ¡c >90% bÃ¬nh luáº­n cá»§a khÃ¡ch hÃ ng.  
    - Cung cáº¥p thÃ´ng tin giÃ¡ trá»‹ cho nhÃ£n hÃ ng Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥.  
    - TÄƒng sá»± hÃ i lÃ²ng vÃ  lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng.
    """)

#####################################

elif page == "Project Summary":

    st.image(
        'src/images/intro.png',use_container_width=True,
    )
    # Title
    st.title("ğŸŒŸ **PhÃ¢n Loáº¡i Pháº£n Há»“i KhÃ¡ch HÃ ng Hasaki.vn** ğŸŒŸ")

    # Problem Section
    st.subheader("1. Váº¥n Ä‘á» ğŸš©")
    st.markdown("""
    Hasaki.vn sá»Ÿ há»¯u lÆ°á»£ng lá»›n dá»¯ liá»‡u tá»« cÃ¡c bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng, tuy nhiÃªn:
    - ğŸš« **KhÃ´ng thá»ƒ xá»­ lÃ½ pháº£n há»“i nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c.**  
    - ğŸ¤” **KhÃ³ xÃ¡c Ä‘á»‹nh pháº£n há»“i tÃ­ch cá»±c, tiÃªu cá»±c hay trung tÃ­nh.**  
    - ğŸ•’ **Tá»‘n thá»i gian Ä‘á»ƒ sá»­ dá»¥ng pháº£n há»“i cho viá»‡c cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥.**
    """)

    # Objective Section
    st.subheader("2. Má»¥c tiÃªu ğŸ¯")
    st.markdown("""
    **XÃ¢y dá»±ng há»‡ thá»‘ng dá»± Ä‘oÃ¡n cáº£m xÃºc trong pháº£n há»“i khÃ¡ch hÃ ng** nháº±m:
    - ğŸ“Š **PhÃ¢n loáº¡i cÃ¡c bÃ¬nh luáº­n** thÃ nh 2 loáº¡i: **tÃ­ch cá»±c, tiÃªu cá»±c**.  
    - ğŸ’¡ GiÃºp Hasaki vÃ  Ä‘á»‘i tÃ¡c:
        - Hiá»ƒu nhanh Ã½ kiáº¿n khÃ¡ch hÃ ng.
        - **Cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥** dá»±a trÃªn pháº£n há»“i thá»±c táº¿.
        - **TÄƒng má»©c Ä‘á»™ hÃ i lÃ²ng vÃ  trung thÃ nh** cá»§a khÃ¡ch hÃ ng.
    """)

    # Solution Section
    st.subheader("3. Giáº£i phÃ¡p ğŸ’¡")
    st.markdown("""
    ğŸ› ï¸ **Há»‡ thá»‘ng dá»± Ä‘oÃ¡n pháº£n há»“i** sáº½ Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i cÃ¡c bÆ°á»›c:
    1. **Thu tháº­p dá»¯ liá»‡u**: Tá»« pháº§n bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng trÃªn Hasaki.vn.  
    2. **Xá»­ lÃ½ dá»¯ liá»‡u**:
        - LÃ m sáº¡ch dá»¯ liá»‡u (loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, stop words).
        - Chuáº©n hÃ³a vÄƒn báº£n (chuyá»ƒn vá» chá»¯ thÆ°á»ng, tÃ¡ch tá»« báº±ng NLP).  
    3. **XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y/há»c sÃ¢u**:
        - Logistic Regression, Random Forest, hoáº·c mÃ´ hÃ¬nh transformer nhÆ° BERT.  
    4. **Triá»ƒn khai há»‡ thá»‘ng**:
        - TÃ­ch há»£p mÃ´ hÃ¬nh trÃªn website Ä‘á»ƒ phÃ¢n loáº¡i pháº£n há»“i theo thá»i gian thá»±c.
    5. **ÄÃ¡nh giÃ¡ vÃ  cáº£i thiá»‡n**:
        - Dá»±a trÃªn chá»‰ sá»‘ Precision, Recall, F1-Score.
    """)

    # Add Image/Diagram to Illustrate the Solution
    st.image(
        "src/images/process.png",
        caption="Minh há»a quy trÃ¬nh phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.",
        use_container_width=True,
    )

    # Expected Outcomes Section
    st.subheader("4. Káº¿t quáº£ ká»³ vá»ng âœ…")
    st.markdown("""
    - **ChÃ­nh xÃ¡c â‰¥90%** trong phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.  
    - **Cung cáº¥p phÃ¢n tÃ­ch thá»i gian thá»±c** cho Hasaki vÃ  Ä‘á»‘i tÃ¡c.  
    - TÄƒng sá»± hÃ i lÃ²ng vÃ  lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng thÃ´ng qua cÃ¡c cáº£i tiáº¿n.
    """)

    # # Interactive Demo Placeholder (Optional)
    # st.subheader("5. Tráº£i nghiá»‡m máº«u ğŸ’»")
    # st.markdown("**Nháº­p bÃ¬nh luáº­n cá»§a báº¡n bÃªn dÆ°á»›i Ä‘á»ƒ kiá»ƒm tra dá»± Ä‘oÃ¡n cáº£m xÃºc (tÃ­ch cá»±c/tiÃªu cá»±c):**")
    # user_input = st.text_area("Nháº­p bÃ¬nh luáº­n khÃ¡ch hÃ ng:")
    # if user_input:
    #     # Placeholder Prediction Logic
    #     # Replace this logic with your trained model's prediction
    #     sentiment = "TÃ­ch cá»±c" if "tá»‘t" in user_input.lower() else "TiÃªu cá»±c"
    #     st.success(f"ğŸŒŸ **Dá»± Ä‘oÃ¡n cáº£m xÃºc**: {sentiment}")

#####################################

elif page == "Sentiment Analysis":
    image = Image.open("src/images/process.png")
    st.image(image, caption="Hasaki.VN - Quality & Trust", use_container_width=True)

    pkl_filemodel = "src/models/logreg_model.pkl" 
    with open(pkl_filemodel, 'rb') as file:  
        lgr_model_sentiment = pickle.load(file)
    # doc model count len
    pkl_count = "src/models/tfidf_vectorizer.pkl"  
    with open(pkl_count, 'rb') as file:  
        tfidf_vectorizer = pickle.load(file)

    plk_scaler = "src/models/minmax_scaler.pkl"
    with open(plk_scaler, 'rb') as file:
        scaler = pickle.load(file)

    # Header
    st.title("ğŸŒŸ Skincare Feedback Analyzer ğŸŒŸ")
    st.write("Is your product **glowing up** your customers or causing a **breakout**? Let's find out!")

    # Add Banner Image
    st.image(
        "src/images/classify.png", 
        caption="âœ¨ **Discover customer insights for flawless skincare experiences**",
        use_container_width=True,
    )

    # Introductory Text
    st.markdown("""
        ğŸ§–â€â™€ï¸ **What does this app do?**  
        - Analyzes customer reviews on your skincare products.  
        - Detects if the feedback is **Positive** ğŸ’– (smooth skin ahead!) or **Negative** ğŸ’” (time to rethink).  
        - Helps you make data-driven decisions to keep your customers glowing!  
    """)

    # Streamlit App
    st.subheader("ğŸš€ Input Customer Feedback for Sentiment Analysis")

    flag = False
    lines = None
    data_type = st.radio("How would you like to provide customer feedback?", options=("ğŸ“ Type it manually", "ğŸ“ Upload a file"))

    if data_type == "ğŸ“ Upload a file":
        # Upload file
        uploaded_file = st.file_uploader("Upload a CSV or TXT file with customer feedback", type=['txt', 'csv'])
        if uploaded_file is not None:
            try:
                # Read data
                if uploaded_file.name.endswith('.csv'):
                    lines = pd.read_csv(uploaded_file, header=None)
                else:
                    lines = pd.read_table(uploaded_file, header=None)
                
                st.write("ğŸ“‚ **Uploaded Data Preview:**")
                st.dataframe(lines)
                lines = lines[0]  # Select the first column for processing
                flag = True
            except Exception as e:
                st.error(f"ğŸš¨ Oops! Couldnâ€™t read the file: {e}")

    if data_type == "ğŸ“ Type it manually":
        content = st.text_area(label="Write a customer's feedback:", placeholder="e.g., This moisturizer is life-changing!")
        if content != "":
            lines = np.array([content])  # Convert input to a NumPy array
            flag = True

    if flag:
        st.subheader("ğŸ§ Processed Feedback")
        if len(lines) > 0:
            st.code(lines, language="plaintext")

            new_reviews = [str(line) for line in lines]
            
            # Transform data using the vectorizer
            x_new = tfidf_vectorizer.transform(new_reviews)

            # Create a DataFrame for the new reviews
            df_new_review = pd.DataFrame(x_new.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

            # Add and scale the 'content_length' feature like you did during training
            df_new_review['content_length'] = [len(review) for review in new_reviews]
            df_new_review['content_length_scaled'] = scaler.transform(df_new_review[['content_length']]) # Use the same scaler from training

            # Combine features
            new_reviews_combined = sp.hstack((x_new, df_new_review[['content_length_scaled']]))

            # Predict sentiment
            y_pred_new = lgr_model_sentiment.predict(new_reviews_combined)
            
            # Map predictions to sentiment labels
            sentiment_labels = {0: "ğŸ’” Negative", 1: "ğŸ’– Positive"}
            predictions = [sentiment_labels[pred] for pred in y_pred_new]
            
            # Display predictions
            st.subheader("ğŸ¯ Feedback Analysis Results:")
            for i, line in enumerate(lines):
                st.markdown(f"""
                - **Feedback**: {line}  
                - **Sentiment**: {predictions[i]}  
                """)
                # Add fun reactions based on sentiment
                if predictions[i] == "ğŸ’– Positive":
                    st.success("âœ¨ Skincare success! Your customers are glowing!")
                else:
                    st.error("ğŸ›‘ Skincare alert! Looks like thereâ€™s room for improvement.")