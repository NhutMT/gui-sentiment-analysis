import streamlit as st
from PIL import Image
import pickle
import pandas as pd
import numpy as np
import scipy.sparse as sp

st.set_page_config(page_title="Sentiment Analysis System", page_icon=":shopping_cart:", layout="wide")

# Sidebar for navigation
menu = ["Home", "Hasaki",'Project Summary', "Sentiment Analysis"]

st.sidebar.title("Navigation")
page = st.sidebar.selectbox("Choose a page", menu)

# Subheader with an icon for "Giáº£ng viÃªn hÆ°á»›ng dáº«n"
st.sidebar.markdown(
    """
    <h3 style="display: flex; align-items: center; font-size: 18px;">
        ğŸ‘©â€ğŸ« <span style="margin-left: 8px;">Giáº£ng viÃªn hÆ°á»›ng dáº«n</span>
    </h3>
    """,
    unsafe_allow_html=True,
)
st.sidebar.markdown("* [CÃ´ Khuáº¥t ThÃ¹y PhÆ°Æ¡ng](https://csc.edu.vn/giao-vien~37#)")


# Subheader with an icon for "NgÃ y bÃ¡o cÃ¡o tá»‘t nghiá»‡p"
st.sidebar.markdown(
    """
    <h3 style="display: flex; align-items: center; font-size: 18px;">
        ğŸ“… <span style="margin-left: 8px;">NgÃ y bÃ¡o cÃ¡o tá»‘t nghiá»‡p:</span>
    </h3>
    """,
    unsafe_allow_html=True,
)
st.sidebar.write("16/12/2024")

# Add spacer for footer positioning
st.sidebar.markdown("<div style='height: 200px;'></div>", unsafe_allow_html=True)

# Sidebar footer
st.sidebar.markdown(
    """
    <style>
        .footer {
            text-align: center;
            font-size: 12px;
        }
        hr {
            border: 1px solid gray;
        }
    </style>
    <div class="footer">
        <hr>
        <p>Â© 2024 Hasaki Sentiment Analysis System</p>
    </div>
    """,
    unsafe_allow_html=True,
)

# Main page logic
if page == "Home":
    # Banner Image
    image = Image.open("src/images/hasaki_banner_2.jpg")
    st.image(image, caption="Sentiment Analysis - Understand Your Customers", use_container_width=True)

    # Project Objective
    st.header("Project Objective")
    st.markdown("""
        This project focuses on developing a **Sentiment Analysis System** to:
        - Analyze customer feedback and reviews.
        - Classify sentiments into categories: **Positive**, **Negative**.
        - Provide actionable insights to improve products and services.
    """)

    # Display Lottie Animation
    image = Image.open("src/images/home.png")
    st.image(image, caption="Sentiment Analysis - Understand Your Customers", use_container_width=True)

    # Methodology
    st.header("Methodology ğŸ“‹")
    st.markdown("""
    ğŸ¤– **Steps to Build the Sentiment Analysis System**:  
    1. **Data Collection**: Collect feedback and reviews from various platforms.  
    2. **Data Preprocessing**: Clean and preprocess the text data using NLP techniques.  
    3. **Model Training**: Train machine learning or deep learning models to classify sentiments.  
    4. **Deployment**: Integrate the sentiment classifier into a real-time system for actionable insights.
    """)

    # Team Section
    st.header("Our Team")
    col1, col2 = st.columns(2)

    with col1:
        st.write("### MÃ£ Tháº¿ Nhá»±t")
        image1 = Image.open("src/images/A.jpg")
        st.image(image1, caption="MÃ£ Tháº¿ Nhá»±t - Data Scientist", use_container_width=True)

    with col2:
        st.write("### Tá»« Thá»‹ Thanh XuÃ¢n")
        image2 = Image.open("src/images/B.jpg")
        st.image(image2, caption="Tá»« Thá»‹ Thanh XuÃ¢n - Machine Learning Engineer", use_container_width=True)

    # Footer
    st.markdown("""
    ---
    **Â© 2024 Sentiment Analysis System** | Developed with â¤ï¸ by [MÃ£ Tháº¿ Nhá»±t & Tá»« Thá»‹ Thanh XuÃ¢n]
    """)

#####################################

elif page == "Hasaki":
    
    # Title
    st.title("ğŸŒŸ **Giá»›i thiá»‡u vá» HASAKI.VN** ğŸŒŸ")
    # Banner Image
    image = Image.open("src/images/hasaki_banner_2.jpg")
    st.image(image, caption="Hasaki.VN - Quality & Trust", use_container_width=True)
    # Introduction Section
    st.subheader("1. Tá»•ng quan vá» HASAKI")
    st.markdown("""
    **HASAKI.VN** lÃ  há»‡ thá»‘ng cá»­a hÃ ng má»¹ pháº©m chÃ­nh hÃ£ng vÃ  dá»‹ch vá»¥ chÄƒm sÃ³c sáº¯c Ä‘áº¹p chuyÃªn sÃ¢u, vá»›i:  
    - ğŸ›’ **Há»‡ thá»‘ng cá»­a hÃ ng tráº£i dÃ i trÃªn toÃ n quá»‘c.**  
    - ğŸ¤ **LÃ  Ä‘á»‘i tÃ¡c phÃ¢n phá»‘i chiáº¿n lÆ°á»£c táº¡i Viá»‡t Nam** cá»§a hÃ ng loáº¡t thÆ°Æ¡ng hiá»‡u má»¹ pháº©m lá»›n.  
    - ğŸŒ **Ná»n táº£ng trá»±c tuyáº¿n** giÃºp khÃ¡ch hÃ ng dá»… dÃ ng:
        - Lá»±a chá»n sáº£n pháº©m.  
        - Xem Ä‘Ã¡nh giÃ¡/nháº­n xÃ©t thá»±c táº¿.  
        - Äáº·t mua hÃ ng nhanh chÃ³ng.  
    """)

    # Divider
    st.divider()

    # Problem Section
    st.subheader("2. Váº¥n Ä‘á» Ä‘áº·t ra ğŸš©")
    st.markdown("""
    ğŸ§ **CÃ¢u há»i Ä‘áº·t ra:**  
    - LÃ m tháº¿ nÃ o Ä‘á»ƒ **cÃ¡c nhÃ£n hÃ ng hiá»ƒu rÃµ hÆ¡n vá» khÃ¡ch hÃ ng**?  
    - LÃ m sao Ä‘á»ƒ biáº¿t **khÃ¡ch hÃ ng Ä‘Ã¡nh giÃ¡ gÃ¬ vá» sáº£n pháº©m**?  
    - LÃ m cÃ¡ch nÃ o Ä‘á»ƒ tá»« pháº£n há»“i Ä‘Ã³, cÃ¡c nhÃ£n hÃ ng cÃ³ thá»ƒ:  
        - **Cáº£i thiá»‡n cháº¥t lÆ°á»£ng sáº£n pháº©m.**  
        - **NÃ¢ng cáº¥p dá»‹ch vá»¥ Ä‘i kÃ¨m.**  
    """)

    # Divider
    st.divider()

    # Goal Section
    st.subheader("3. Má»¥c tiÃªu ğŸ¯")
    st.markdown("""
    - ğŸ’¡ **Thu tháº­p vÃ  phÃ¢n tÃ­ch Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng** Ä‘á»ƒ cung cáº¥p thÃ´ng tin giÃ¡ trá»‹ cho cÃ¡c nhÃ£n hÃ ng.  
    - ğŸ“Š GiÃºp cÃ¡c nhÃ£n hÃ ng hiá»ƒu sÃ¢u hÆ¡n vá» **sá»Ÿ thÃ­ch, nhu cáº§u vÃ  tráº£i nghiá»‡m thá»±c táº¿** cá»§a khÃ¡ch hÃ ng.  
    - ğŸš€ TÄƒng sá»± hÃ i lÃ²ng vÃ  trung thÃ nh cá»§a khÃ¡ch hÃ ng thÃ´ng qua viá»‡c cáº£i tiáº¿n sáº£n pháº©m vÃ  dá»‹ch vá»¥.
    """)

    # Divider
    st.divider()

    # Methodology Section
    st.subheader("4. PhÆ°Æ¡ng phÃ¡p ğŸ“‹")
    st.markdown("""
    ğŸ¤– **XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c/tiÃªu cá»±c**  
    1. **Thu tháº­p dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡** tá»« khÃ¡ch hÃ ng trÃªn ná»n táº£ng HASAKI.  
    2. **Xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)**:
        - Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t vÃ  tá»« dÆ° thá»«a.
        - TÃ¡ch tá»« vÃ  chuáº©n hÃ³a vÄƒn báº£n báº±ng cÃ´ng cá»¥ NLP nhÆ° `underthesea` hoáº·c ``.  
    3. **Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y**:
        - Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n nhÆ° Logistic Regression, Random Forest.  
    4. **PhÃ¢n loáº¡i cáº£m xÃºc**:
        - DÃ¡n nhÃ£n bÃ¬nh luáº­n: **TÃ­ch cá»±c** hoáº·c **TiÃªu cá»±c**.  
    5. **Triá»ƒn khai há»‡ thá»‘ng**:
        - TÃ­ch há»£p mÃ´ hÃ¬nh vÃ o ná»n táº£ng Ä‘á»ƒ xá»­ lÃ½ bÃ¬nh luáº­n trong thá»i gian thá»±c.  
    """)


    st.image(
    "src/images/1.jpg", 
    caption="âœ¨ **PhÃ¢n loáº¡i bÃ¬nh luáº­n tÃ­ch cá»±c vÃ  tiÃªu cá»±c** giÃºp nhÃ£n hÃ ng hiá»ƒu rÃµ hÆ¡n cáº£m xÃºc cá»§a khÃ¡ch hÃ ng vÃ  cáº£i thiá»‡n cháº¥t lÆ°á»£ng sáº£n pháº©m.",
    use_container_width=True,
    )

    st.markdown("""
    ğŸ’¡ **Minh há»a**:  
    - BÃ¬nh luáº­n tÃ­ch cá»±c Ä‘Æ°á»£c phÃ¢n tÃ­ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh nhá»¯ng Ä‘iá»ƒm ná»•i báº­t mÃ  khÃ¡ch hÃ ng yÃªu thÃ­ch.  
    - BÃ¬nh luáº­n tiÃªu cá»±c Ä‘Æ°á»£c khai thÃ¡c Ä‘á»ƒ tÃ¬m ra cÃ¡c váº¥n Ä‘á» cáº§n cáº£i thiá»‡n.  
    ğŸ“Š **TÄƒng kháº£ nÄƒng hÃ nh Ä‘á»™ng:** Giáº£i phÃ¡p nÃ y giÃºp nhÃ£n hÃ ng tá»‘i Æ°u hÃ³a sáº£n pháº©m vÃ  dá»‹ch vá»¥.
    """)

    # Divider
    st.divider()

    # Call-to-Action
    st.markdown("""
    ğŸ’¡ **Káº¿t quáº£ ká»³ vá»ng**:  
    - PhÃ¢n loáº¡i chÃ­nh xÃ¡c >90% bÃ¬nh luáº­n cá»§a khÃ¡ch hÃ ng.  
    - Cung cáº¥p thÃ´ng tin giÃ¡ trá»‹ cho nhÃ£n hÃ ng Ä‘á»ƒ cáº£i thiá»‡n sáº£n pháº©m vÃ  dá»‹ch vá»¥.  
    - TÄƒng sá»± hÃ i lÃ²ng vÃ  lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng.
    """)

#####################################

elif page == "Project Summary":

    st.image(
        'src/images/intro.png',use_container_width=True,
    )
    # Title
    st.title("ğŸŒŸ **PhÃ¢n Loáº¡i Pháº£n Há»“i KhÃ¡ch HÃ ng Hasaki.vn** ğŸŒŸ")

    # Problem Section
    st.subheader("1. Váº¥n Ä‘á» ğŸš©")
    st.markdown("""
    Hasaki.vn sá»Ÿ há»¯u lÆ°á»£ng lá»›n dá»¯ liá»‡u tá»« cÃ¡c bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng, tuy nhiÃªn:
    - ğŸš« **KhÃ´ng thá»ƒ xá»­ lÃ½ pháº£n há»“i nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c.**  
    - ğŸ¤” **KhÃ³ xÃ¡c Ä‘á»‹nh pháº£n há»“i tÃ­ch cá»±c, tiÃªu cá»±c hay trung tÃ­nh.**  
    - ğŸ•’ **Tá»‘n thá»i gian Ä‘á»ƒ sá»­ dá»¥ng pháº£n há»“i cho viá»‡c cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥.**
    """)

    # Objective Section
    st.subheader("2. Má»¥c tiÃªu ğŸ¯")
    st.markdown("""
    **XÃ¢y dá»±ng há»‡ thá»‘ng dá»± Ä‘oÃ¡n cáº£m xÃºc trong pháº£n há»“i khÃ¡ch hÃ ng** nháº±m:
    - ğŸ“Š **PhÃ¢n loáº¡i cÃ¡c bÃ¬nh luáº­n** thÃ nh 2 loáº¡i: **tÃ­ch cá»±c, tiÃªu cá»±c**.  
    - ğŸ’¡ GiÃºp Hasaki vÃ  Ä‘á»‘i tÃ¡c:
        - Hiá»ƒu nhanh Ã½ kiáº¿n khÃ¡ch hÃ ng.
        - **Cáº£i thiá»‡n sáº£n pháº©m/dá»‹ch vá»¥** dá»±a trÃªn pháº£n há»“i thá»±c táº¿.
        - **TÄƒng má»©c Ä‘á»™ hÃ i lÃ²ng vÃ  trung thÃ nh** cá»§a khÃ¡ch hÃ ng.
    """)

    # Solution Section
    st.subheader("3. Giáº£i phÃ¡p ğŸ’¡")
    st.markdown("""
    ğŸ› ï¸ **Há»‡ thá»‘ng dá»± Ä‘oÃ¡n pháº£n há»“i** sáº½ Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i cÃ¡c bÆ°á»›c:
    1. **Thu tháº­p dá»¯ liá»‡u**: Tá»« pháº§n bÃ¬nh luáº­n vÃ  Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng trÃªn Hasaki.vn.  
    2. **Xá»­ lÃ½ dá»¯ liá»‡u**:
        - LÃ m sáº¡ch dá»¯ liá»‡u (loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, stop words).
        - Chuáº©n hÃ³a vÄƒn báº£n (chuyá»ƒn vá» chá»¯ thÆ°á»ng, tÃ¡ch tá»« báº±ng NLP).  
    3. **XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y/há»c sÃ¢u**:
        - Logistic Regression, Random Forest, hoáº·c mÃ´ hÃ¬nh transformer nhÆ° BERT.  
    4. **Triá»ƒn khai há»‡ thá»‘ng**:
        - TÃ­ch há»£p mÃ´ hÃ¬nh trÃªn website Ä‘á»ƒ phÃ¢n loáº¡i pháº£n há»“i theo thá»i gian thá»±c.
    5. **ÄÃ¡nh giÃ¡ vÃ  cáº£i thiá»‡n**:
        - Dá»±a trÃªn chá»‰ sá»‘ Precision, Recall, F1-Score.
    """)

    # Add Image/Diagram to Illustrate the Solution
    st.image(
        "src/images/process.png",
        caption="Minh há»a quy trÃ¬nh phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.",
        use_container_width=True,
    )

    # Expected Outcomes Section
    st.subheader("4. Káº¿t quáº£ ká»³ vá»ng âœ…")
    st.markdown("""
    - **ChÃ­nh xÃ¡c â‰¥90%** trong phÃ¢n loáº¡i pháº£n há»“i khÃ¡ch hÃ ng.  
    - **Cung cáº¥p phÃ¢n tÃ­ch thá»i gian thá»±c** cho Hasaki vÃ  Ä‘á»‘i tÃ¡c.  
    - TÄƒng sá»± hÃ i lÃ²ng vÃ  lÃ²ng trung thÃ nh cá»§a khÃ¡ch hÃ ng thÃ´ng qua cÃ¡c cáº£i tiáº¿n.
    """)

    # # Interactive Demo Placeholder (Optional)
    # st.subheader("5. Tráº£i nghiá»‡m máº«u ğŸ’»")
    # st.markdown("**Nháº­p bÃ¬nh luáº­n cá»§a báº¡n bÃªn dÆ°á»›i Ä‘á»ƒ kiá»ƒm tra dá»± Ä‘oÃ¡n cáº£m xÃºc (tÃ­ch cá»±c/tiÃªu cá»±c):**")
    # user_input = st.text_area("Nháº­p bÃ¬nh luáº­n khÃ¡ch hÃ ng:")
    # if user_input:
    #     # Placeholder Prediction Logic
    #     # Replace this logic with your trained model's prediction
    #     sentiment = "TÃ­ch cá»±c" if "tá»‘t" in user_input.lower() else "TiÃªu cá»±c"
    #     st.success(f"ğŸŒŸ **Dá»± Ä‘oÃ¡n cáº£m xÃºc**: {sentiment}")

#####################################

elif page == "Sentiment Analysis":
    image = Image.open("src/images/process.png")
    st.image(image, caption="Hasaki.VN - Quality & Trust", use_container_width=True)

    pkl_filemodel = "src/models/logreg_model.pkl" 
    with open(pkl_filemodel, 'rb') as file:  
        lgr_model_sentiment = pickle.load(file)
    # doc model count len
    pkl_count = "src/models/tfidf_vectorizer.pkl"  
    with open(pkl_count, 'rb') as file:  
        tfidf_vectorizer = pickle.load(file)

    plk_scaler = "src/models/minmax_scaler.pkl"
    with open(plk_scaler, 'rb') as file:
        scaler = pickle.load(file)

    # Header
    st.title("ğŸŒŸ Skincare Feedback Analyzer ğŸŒŸ")
    st.write("Is your product **glowing up** your customers or causing a **breakout**? Let's find out!")

    # Add Banner Image
    st.image(
        "src/images/classify.png", 
        caption="âœ¨ **Discover customer insights for flawless skincare experiences**",
        use_container_width=True,
    )

    # Introductory Text
    st.markdown("""
        ğŸ§–â€â™€ï¸ **What does this app do?**  
        - Analyzes customer reviews on your skincare products.  
        - Detects if the feedback is **Positive** ğŸ’– (smooth skin ahead!) or **Negative** ğŸ’” (time to rethink).  
        - Helps you make data-driven decisions to keep your customers glowing!  
    """)

    # Streamlit App
    st.subheader("ğŸš€ Input Customer Feedback for Sentiment Analysis")

    flag = False
    lines = None
    data_type = st.radio("How would you like to provide customer feedback?", options=("ğŸ“ Type it manually", "ğŸ“ Upload a file"))

    if data_type == "ğŸ“ Upload a file":
        # Upload file
        uploaded_file = st.file_uploader("Upload a CSV or TXT file with customer feedback", type=['txt', 'csv'])
        if uploaded_file is not None:
            try:
                # Read data
                if uploaded_file.name.endswith('.csv'):
                    lines = pd.read_csv(uploaded_file, header=None)
                else:
                    lines = pd.read_table(uploaded_file, header=None)
                
                st.write("ğŸ“‚ **Uploaded Data Preview:**")
                st.dataframe(lines)
                lines = lines[0]  # Select the first column for processing
                flag = True
            except Exception as e:
                st.error(f"ğŸš¨ Oops! Couldnâ€™t read the file: {e}")

    if data_type == "ğŸ“ Type it manually":
        content = st.text_area(label="Write a customer's feedback:", placeholder="e.g., This moisturizer is life-changing!")
        if content != "":
            lines = np.array([content])  # Convert input to a NumPy array
            flag = True

    if flag:
        st.subheader("ğŸ§ Processed Feedback")
        if len(lines) > 0:
            st.code(lines, language="plaintext")

            new_reviews = [str(line) for line in lines]
            
            # Transform data using the vectorizer
            x_new = tfidf_vectorizer.transform(new_reviews)

            # Create a DataFrame for the new reviews
            df_new_review = pd.DataFrame(x_new.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

            # Add and scale the 'content_length' feature like you did during training
            df_new_review['content_length'] = [len(review) for review in new_reviews]
            df_new_review['content_length_scaled'] = scaler.transform(df_new_review[['content_length']]) # Use the same scaler from training

            # Combine features
            new_reviews_combined = sp.hstack((x_new, df_new_review[['content_length_scaled']]))

            # Predict sentiment
            y_pred_new = lgr_model_sentiment.predict(new_reviews_combined)
            
            # Map predictions to sentiment labels
            sentiment_labels = {0: "ğŸ’” Negative", 1: "ğŸ’– Positive"}
            predictions = [sentiment_labels[pred] for pred in y_pred_new]
            
            # Display predictions
            st.subheader("ğŸ¯ Feedback Analysis Results:")
            for i, line in enumerate(lines):
                st.markdown(f"""
                - **Feedback**: {line}  
                - **Sentiment**: {predictions[i]}  
                """)
                # Add fun reactions based on sentiment
                if predictions[i] == "ğŸ’– Positive":
                    st.success("âœ¨ Skincare success! Your customers are glowing!")
                else:
                    st.error("ğŸ›‘ Skincare alert! Looks like thereâ€™s room for improvement.")